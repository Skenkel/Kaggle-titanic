{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures, LabelEncoder,FunctionTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "titanic = pd.read_csv('train.csv')\n",
    "testdf = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic['Cabin'] =titanic['Cabin'].fillna(value='?')\n",
    "titanic['Embarked'] =titanic['Embarked'].fillna(value='S')\n",
    "titanic['Age'] =titanic['Age'].fillna(value='?')\n",
    "testdf['Cabin'] =testdf['Cabin'].fillna(value='?')\n",
    "testdf['Embarked'] =testdf['Embarked'].fillna(value='S')\n",
    "testdf['Age'] =testdf['Age'].fillna(value='?')\n",
    "testdf.loc[152,'Fare']=13.6755 # we fill in the missing fare from the test data here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def titlepull(title_string):\n",
    "    title_list = title_string.split()\n",
    "    for possible_title in title_list:\n",
    "        if possible_title[-1] == '.':\n",
    "            return possible_title\n",
    "def cabinpull(cabin_string):\n",
    "    if cabin_string[0]=='?':\n",
    "        return '?'\n",
    "    else:\n",
    "        return cabin_string[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing to understand is that before you do a pipline, you must convert categorical variables into the pandas category object. To do this, you must check the possible values present in both training and test data, and ensure that the category contains all possibilities. Not doing this will lead to estimators working on the training data, but it will fail on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic['Deck']=titanic.Cabin.apply(cabinpull)\n",
    "titanic['Title']= titanic.Name.apply(titlepull)\n",
    "testdf['Deck']=testdf.Cabin.apply(cabinpull)\n",
    "testdf['Title']= testdf.Name.apply(titlepull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "?    687\n",
       "C     59\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "A     15\n",
       "F     13\n",
       "G      4\n",
       "T      1\n",
       "Name: Deck, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.Deck.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "?    327\n",
       "C     35\n",
       "B     18\n",
       "D     13\n",
       "E      9\n",
       "F      8\n",
       "A      7\n",
       "G      1\n",
       "Name: Deck, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.Deck.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missing deck information is a real problem: even though from EDA I know that cabin matters, it is simply missing on too much of the data to be safely imputed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decks_list = ['?','C','B','D','E','F','A','G','T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.          517\n",
       "Miss.        182\n",
       "Mrs.         125\n",
       "Master.       40\n",
       "Dr.            7\n",
       "Rev.           6\n",
       "Major.         2\n",
       "Col.           2\n",
       "Mlle.          2\n",
       "Sir.           1\n",
       "Countess.      1\n",
       "Lady.          1\n",
       "Capt.          1\n",
       "Don.           1\n",
       "Ms.            1\n",
       "Jonkheer.      1\n",
       "Mme.           1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.        240\n",
       "Miss.       78\n",
       "Mrs.        72\n",
       "Master.     21\n",
       "Col.         2\n",
       "Rev.         2\n",
       "Dona.        1\n",
       "Ms.          1\n",
       "Dr.          1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.Title.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are decisions to be made at this step that are work making after having done eda. Specifically, I'm leaving the decks as dummies, rather than transforming the decks into a numeric value based on counting from the bottom or top deck. \n",
    "In the case of the titles, I'm going to use Royalty, and Officer to collect all of the weird titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mappings = {\n",
    "    'Dona.':'Royalty',\n",
    "    'Countess.':'Royalty',\n",
    "    'Sir.':'Royalty',\n",
    "    'Jonkheer.':'Royalty',\n",
    "    'Don.':'Royalty',\n",
    "    'Lady.':'Royalty',\n",
    "    'Ms.':'Miss.',\n",
    "    'Col.':'Officer',\n",
    "    'Capt.':'Officer',\n",
    "    'Major.':'Officer',\n",
    "    'Col.':'Officer',\n",
    "    'Mlle.':'Miss.',\n",
    "    'Mme.':'Mrs.',\n",
    "    'Mrs.':'Mrs.',\n",
    "    'Miss.':'Miss',\n",
    "    'Mr.':'Mr.',\n",
    "    'Master.':'Master.',\n",
    "    'Dr.':'Dr.',\n",
    "    'Rev.':'Rev.'\n",
    "    \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Title'].map(name_mappings, )\n",
    "\n",
    "titanic['Title']= titanic['Title'].map(name_mappings)\n",
    "testdf['Title']= testdf['Title'].map(name_mappings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.        517\n",
       "Miss       182\n",
       "Mrs.       126\n",
       "Master.     40\n",
       "Dr.          7\n",
       "Rev.         6\n",
       "Officer      5\n",
       "Royalty      5\n",
       "Miss.        3\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.Title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Deck, Title]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic[titanic['Title'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Deck, Title]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf[testdf['Title'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validtitles = list(set(name_mappings.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, to explain this code further, I use the dictionary I've made for the map function and return all of the values. With all of the values, I turn them into a set, which ignores duplicates, then I transform that into a list to be fed into the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Title = titanic['Title'].astype(\"category\", categories=validtitles, ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdf.Title = testdf['Title'].astype(\"category\", categories=validtitles, ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic.Deck = titanic['Deck'].astype(\"category\", categories=decks_list, ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdf.Deck = testdf['Deck'].astype(\"category\", categories=decks_list, ordered=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I wanted to do my 'Dead_Wife' features, I would need to do that outside of a pipline. This is because pipelines cannot 'remember' things from previous runs. This is also a great indication that my 'dead spouse' feature is fun little hack for this dataset, but is unlikely to be replicated in most environments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def titlepull(title_string):\n",
    "    title_list = title_string.split()\n",
    "    for possible_title in title_list:\n",
    "        if possible_title[-1] == '.':\n",
    "            return possible_title\n",
    "def cabinpull(cabin_string):\n",
    "    if cabin_string[0]=='?':\n",
    "        return '?'\n",
    "    else:\n",
    "        return cabin_string[0]\n",
    "    \n",
    "def tit_deck(df):\n",
    "    deck_dummies = pd.get_dummies(df.Deck,prefix='Deck')\n",
    "    return deck_dummies\n",
    "\n",
    "tit_deck_tf = FunctionTransformer(tit_deck,validate=False)\n",
    "\n",
    "def tit_class(df):\n",
    "    pclass_dummies=   pd.get_dummies(df.Pclass,prefix='plcass')\n",
    "    return pclass_dummies\n",
    "\n",
    "tit_class_tf = FunctionTransformer(tit_class, validate=False)\n",
    "\n",
    "def tit_title(df):\n",
    "    title_dummies= pd.get_dummies(df.Title,prefix='Title')\n",
    "    return title_dummies\n",
    "\n",
    "tit_title_tf  = FunctionTransformer(tit_title, validate=False)\n",
    "\n",
    "\n",
    "\n",
    "def tit_features(df):\n",
    "    df['IsFemale'] = (df.Sex=='female').astype(int)\n",
    "    return df[['IsFemale','Fare','Pclass']]\n",
    "\n",
    "tit_features_tf  = FunctionTransformer(tit_features, validate=False)\n",
    "\n",
    "def tit_family(df):\n",
    "    df['FamilyCount']= (df['SibSp'])+(df['Parch'])\n",
    "    fam_dummies=  pd.get_dummies(df.FamilyCount,prefix='family')\n",
    "    return fam_dummies\n",
    "               \n",
    "tit_family_tf  = FunctionTransformer(tit_family, validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#age_transformers = [('family',tit_family_tf),('class',tit_class_tf),('deck',tit_deck_tf),('features',tit_features_tf),('title',tit_title_tf),('pclass',tit_pclass_tf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_transformers =[('features',tit_features_tf),('title',tit_title_tf),('deck',tit_deck_tf),('class',tit_class_tf)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Explain: Any variable that is dummied, must be objected before. If you do not do this (As I didn't for family, parents, children), when a train test split occur for cross validation, it will find a value of family that is missing from the test split, and it will fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numeric_features(df):\n",
    "    return df.select_dtypes(exclude= ['object'])\n",
    "numeric_features_tf = FunctionTransformer(numeric_features, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fu_age_impute = FeatureUnion(age_transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, by breaking this down into a pipeline, we can turn features on and off by re-running only a few cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knr = KNeighborsRegressor(n_jobs=-1)\n",
    "lr = LinearRegression()\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_impute_pipe_kn =  Pipeline(\n",
    "    [\n",
    "        ('fu_age',fu_age_impute),\n",
    "        ('ss',ss),\n",
    "        ('knr',knr)\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_impute_pipe_lr =  Pipeline(\n",
    "    [\n",
    "        ('fu',fu_age_impute),\n",
    "        ('ss',ss),\n",
    "        ('lr',lr)\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_ages =titanic[(titanic['Age']!='?')]\n",
    "titanic_no_ages = titanic[(titanic['Age']=='?')]\n",
    "\n",
    "test_ages =testdf[(testdf['Age']!='?')]\n",
    "test_no_ages = testdf[(testdf['Age']=='?')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_params = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_age_kn = GridSearchCV(age_impute_pipe_kn, param_grid=age_params, cv=5)\n",
    "gs_age_lr = GridSearchCV(age_impute_pipe_lr, param_grid=age_params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = titanic_ages.drop('Age',axis=1)\n",
    "y_train= titanic_ages['Age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test1 =titanic_no_ages.drop('Age', axis=1)\n",
    "X_test2 = test_no_ages.drop('Age', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.32130031494e+22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "gs_age_lr.fit(X_train,y_train)\n",
    "print(gs_age_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264809838666\n"
     ]
    }
   ],
   "source": [
    "gs_age_kn.fit(X_train,y_train)\n",
    "print(gs_age_kn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('fu_age', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('features', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function tit_features at 0x7fd7106abc80>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y=False, validate=False)), ('title', FunctionTransformer...kowski',\n",
       "          metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "          weights='uniform'))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_impute_pipe_kn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4894247266532521"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_impute_pipe_kn.score(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29.2, 26.2, 35.8, 32.5, 21.2, 31.4, 42.4, 25.2, 21.2, 31.4, 25.8,\n",
       "       31.2, 25.2, 24.2, 38.7, 46.4, 7.4, 31.4, 25.8, 20.6, 25.8, 25.8,\n",
       "       31.4, 24.8, 6.8, 25.8, 49.5, 22.8, 33.0, 29.1, 31.2, 5.8, 41.6,\n",
       "       52.2, 5.4, 10.6, 41.8, 41.2, 28.8, 49.5, 25.2, 26.4, 49.5, 31.4,\n",
       "       5.6, 20.0, 12.5, 11.9, 29.1, 40.8, 49.5, 25.2, 44.8, 25.2, 34.2,\n",
       "       55.0, 46.4, 38.7, 25.2, 30.6, 25.9, 25.8, 30.0, 26.4, 6.0, 40.8,\n",
       "       31.4, 28.8, 38.7, 32.5, 21.2, 21.2, 31.2, 35.8, 25.2, 40.8, 31.4,\n",
       "       42.7, 5.6, 31.4, 28.0, 34.2, 35.8, 31.4, 29.1, 49.5, 28.8, 23.8,\n",
       "       23.8, 25.8, 51.0, 49.5, 25.8, 34.2, 42.7, 29.1, 41.2, 34.2, 5.6,\n",
       "       23.8, 29.3, 31.1, 19.6, 46.4, 25.8, 30.6, 32.5, 21.2, 39.4, 21.2,\n",
       "       33.2, 29.3, 37.6, 23.8, 42.8, 49.5, 25.8, 22.0, 21.2, 25.2, 32.8,\n",
       "       31.2, 25.8, 25.2, 10.2, 32.5, 31.4, 42.6, 28.4, 11.9, 49.5, 42.7,\n",
       "       46.8, 29.5, 26.4, 29.0, 31.4, 21.8, 31.4, 24.8, 40.8, 34.2, 22.0,\n",
       "       26.4, 24.2, 7.4, 40.5, 31.2, 24.2, 34.2, 31.4, 31.4, 43.2, 29.3,\n",
       "       40.6, 30.6, 32.5, 29.3, 42.7, 30.6, 49.5, 10.6, 44.8, 44.6, 29.0,\n",
       "       26.4, 49.5, 21.2, 25.8, 38.7, 26.4, 36.2, 21.2, 10.6, 24.6, 31.4,\n",
       "       6.0], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_impute_pipe_kn.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 14)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'Deck', 'Title', 'IsFemale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch',\n",
       "       'Ticket', 'Fare', 'Cabin', 'Embarked', 'Deck', 'Title', 'IsFemale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
